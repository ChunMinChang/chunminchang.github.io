<html>
  <head>
    <title>WebAudio Different Sample Rates Test</title>
  </head>
  <script>
    function assert_equals(actual, expected, message) {
      if (actual !== expected) {
        throw new Error(
          `Assertion failed: ${message}. Expected ${expected}, got ${actual}.`
        );
      }
    }

    function assert_true(value, message) {
      if (!value) {
        throw new Error(
          `Assertion failed: ${message}. Expected true, got ${value}.`
        );
      }
    }

    function assert_false(value, message) {
      assert_true(!value, message);
    }

    function createSineWaveInput(rate, frequency = 440) {
      const ctx = new AudioContext({ sampleRate: rate });
      const osc = ctx.createOscillator();
      osc.type = "sine";
      osc.frequency.value = frequency;
      const dest = new MediaStreamAudioDestinationNode(ctx);
      osc.connect(dest);
      return { ctx, osc, dest };
    }

    async function waitForMessage(detectorNode, type, eventChecker = null) {
      assert_equals(
        detectorNode.context.state,
        "running",
        `Detector at rate ${detectorNode.context.sampleRate} is closed.`
      );
      assert_equals(
        detectorNode.port.onmessage,
        null,
        "port.onmessage should be null before calling waitForMessage."
      );

      return new Promise((resolve, reject) => {
        let appendix = [];
        detectorNode.port.onmessage = (event) => {
          if (
            !event.data.type ||
            event.data.type != type ||
            (eventChecker && !eventChecker(event.data))
          ) {
            appendix.push(event.data);
            return;
          }
          // Clear the handler after receiving a message.
          detectorNode.port.onmessage = null;
          resolve({ data: event.data, appendix });
        };
      });
    }

    async function createAudioSourceAndSilenceDetector(rate, stream) {
      const ctx = new AudioContext({ sampleRate: rate });
      await ctx.audioWorklet.addModule("silence-detector.js");
      const sourceNode = ctx.createMediaStreamSource(stream);
      const detectorNode = new AudioWorkletNode(ctx, "silence-detector");
      sourceNode.connect(detectorNode);
      detectorNode.connect(ctx.destination);
      sourceNode.connect(ctx.destination);
      return { ctx, sourceNode, detectorNode };
    }

    // Helper function to create test pairs and wait for them to become non-silent.
    async function createAndStartTestPairs(input, dstRates, cloneTracks) {
      // Create multiple MediaStreamAudioSourceNodes with different AudioContext sample rates.
      const pairs = [];
      for (const rate of dstRates) {
        const isolatedStream = new MediaStream(
          cloneTracks
            ? input.dest.stream.getTracks().map((track) => track.clone())
            : input.dest.stream.getTracks()
        );
        pairs.push(
          await createAudioSourceAndSilenceDetector(rate, isolatedStream)
        );
      }

      // Make sure all detectors are not silent after starting the oscillator.
      const msgPromises = pairs.map((p) =>
        waitForMessage(
          p.detectorNode,
          "stateChanged",
          (data) => data.isSilentChanged
        )
      );
      input.osc.start();
      const msgs = await Promise.all(msgPromises);
      msgs.forEach((msg, i) => {
        assert_false(
          msg.data.isSilent,
          `Detector in context with rate ${pairs[i].detectorNode.context.sampleRate} should not be silent after oscillator starts.`
        );
      });

      return pairs;
    }

    // Helper function to query detector states and wait for responses.
    async function queryDetectorStates(pairs) {
      for (const { detectorNode } of pairs) {
        detectorNode.port.postMessage({ command: "queryState" });
      }
      const msgPromises = pairs.map((p) =>
        waitForMessage(p.detectorNode, "stateQueryResponse")
      );
      return await Promise.all(msgPromises);
    }

    function delay(ms) {
      return new Promise((resolve) => setTimeout(resolve, ms));
    }

    // Helper functions to wait for stateChanged messages after performing an action.
    async function waitForStateChangedsAfterAction(
      detectorNodes,
      action,
      eventChecker = null
    ) {
      const msgPromises = detectorNodes.map((node) =>
        waitForMessage(node, "stateChanged", eventChecker)
      );
      await action();
      return await Promise.all(msgPromises);
    }

    async function waitForStateChangedAfterAction(
      detectorNode,
      action,
      eventChecker = null
    ) {
      return (
        await waitForStateChangedsAfterAction(
          [detectorNode],
          action,
          eventChecker
        )
      )[0];
    }

    // Returns the max buffer processing delay (ms) for given analysers.
    function calculateRequiredDelay(nodes, safetyMarginMs = 300) {
      if (!nodes || nodes.length === 0) {
        return 0;
      }

      // Each buffer processing takes processingBlockSize / sampleRate seconds.
      // The default block size is 128 samples.
      const processingBlockSize = 128;
      const maxDurationSec = Math.max(
        ...nodes.map((n) => processingBlockSize / n.context.sampleRate)
      );

      return maxDurationSec * 1000 + safetyMarginMs;
    }

    async function testClosingOneContextStopsOnlyIt(
      tone,
      srcRate,
      dstRates,
      cloneTracks
    ) {
      assert_false(
        dstRates.includes(srcRate),
        "dstRates should not include srcRate."
      );

      const input = createSineWaveInput(srcRate, tone);
      const pairs = await createAndStartTestPairs(input, dstRates, cloneTracks);

      // Verify closing one sourceNode's context stops it without affecting others.

      const pairToClose = pairs.shift();
      await pairToClose.ctx.close();

      await delay(calculateRequiredDelay(pairs.map((p) => p.detectorNode)));

      const msgs = await queryDetectorStates(pairs);
      msgs.forEach((msg, i) => {
        assert_false(
          msg.data.isSilent,
          `Detector in context with rate ${pairs[i].detectorNode.context.sampleRate} should not be silent after closing the first context.`
        );
        assert_equals(
          msg.appendix.length,
          0,
          `Expected no additional messages for detector in context with rate ${pairs[i].detectorNode.context.sampleRate}.`
        );
      });

      // Clean up remaining contexts.

      for (const { ctx } of pairs) {
        await ctx.close();
      }
      input.ctx.close();
    }

    async function testSuspendingOneContextSilencesOnlyIt(
      tone,
      srcRate,
      dstRates,
      cloneTracks
    ) {
      assert_false(
        dstRates.includes(srcRate),
        "dstRates should not include srcRate."
      );

      const input = createSineWaveInput(srcRate, tone);
      const pairs = await createAndStartTestPairs(input, dstRates, cloneTracks);

      // Verify suspending one context silences its detector without impacting others.

      const pairsToCheck = pairs.slice(1);
      const pairToSuspend = pairs[0];

      await pairToSuspend.ctx.suspend();

      const msgs = await queryDetectorStates(pairsToCheck);
      msgs.forEach((msg, i) => {
        assert_false(
          msg.data.isSilent,
          `Detector in context with rate ${pairsToCheck[i].detectorNode.context.sampleRate} should not be silent after suspending the first context.`
        );
        assert_equals(
          msg.appendix.length,
          0,
          `Expected no additional messages for detector in context with rate ${pairsToCheck[i].detectorNode.context.sampleRate}.`
        );
      });

      // Clean up AudioContexts.

      for (const { ctx } of pairs) {
        await ctx.close();
      }
      input.ctx.close();
    }

    async function testDisconnectingOneSourceSilencesOnlyIt(
      tone,
      srcRate,
      dstRates,
      cloneTracks
    ) {
      assert_false(
        dstRates.includes(srcRate),
        "dstRates should not include srcRate."
      );

      const input = createSineWaveInput(srcRate, tone);
      const pairs = await createAndStartTestPairs(input, dstRates, cloneTracks);

      // Verify disconnecting one source node silences its detector without impacting others.

      const pairToDisconnect = pairs[0];
      const pairsToCheck = pairs.slice(1);

      pairToDisconnect.sourceNode.disconnect();

      const msgs = await queryDetectorStates(pairsToCheck);
      msgs.forEach((msg, i) => {
        assert_false(
          msg.data.isSilent,
          `Detector in context with rate ${pairsToCheck[i].detectorNode.context.sampleRate} should not be silent after disconnecting the first source node.`
        );
        assert_equals(
          msg.appendix.length,
          0,
          `Expected no additional messages for detector in context with rate ${pairsToCheck[i].detectorNode.context.sampleRate}.`
        );
      });

      // Clean up AudioContexts.

      for (const { ctx } of pairs) {
        await ctx.close();
      }
      input.ctx.close();
    }

    async function testStoppingOneMediaStream(
      tone,
      srcRate,
      dstRates,
      cloneTracks
    ) {
      assert_false(
        dstRates.includes(srcRate),
        "dstRates should not include srcRate."
      );

      const input = createSineWaveInput(srcRate, tone);
      const pairs = await createAndStartTestPairs(input, dstRates, cloneTracks);

      // Verify stopping the tracks of one MediaStream silences only its detector or all of them.

      const pairToStop = pairs[0];
      const pairsToCheck = pairs.slice(1);

      function stopStream() {
        pairToStop.sourceNode.mediaStream.getTracks().forEach((track) => {
          track.stop();
        });
      }

      // If MediaStreamTracks are cloned, only the one with the stopped stream should be silent.
      // If MediaStreamTracks are shared, all detectors should lose input (silence or no input).
      if (cloneTracks) {
        stopStream();
        await delay(
          calculateRequiredDelay(pairsToCheck.map((p) => p.detectorNode))
        );
        const msgs = await queryDetectorStates(pairsToCheck);
        msgs.forEach((msg, i) => {
          assert_false(
            msg.data.isSilent,
            `Detector in context with rate ${pairsToCheck[i].detectorNode.context.sampleRate} should not be silent after stopping the first stream.`
          );
        });
      } else {
        const msgs = await waitForStateChangedsAfterAction(
          pairsToCheck.map((p) => p.detectorNode),
          stopStream
        );
        // Firefox will lose input, while Chromium-based browsers will get silence from the input.
        msgs.forEach((msg, i) => {
          assert_true(
            !msg.data.hasInput || msg.data.isSilent,
            `Detector in context with rate ${pairsToCheck[i].detectorNode.context.sampleRate} should be silent or have no input after stopping the shared track.`
          );
        });
      }

      // Clean up AudioContexts.

      for (const { ctx } of pairs) {
        await ctx.close();
      }
      input.ctx.close();
    }

    async function testDisablingOneMediaStream(
      tone,
      srcRate,
      dstRates,
      cloneTracks
    ) {
      assert_false(
        dstRates.includes(srcRate),
        "dstRates should not include srcRate."
      );

      const input = createSineWaveInput(srcRate, tone);
      const pairs = await createAndStartTestPairs(input, dstRates, cloneTracks);

      // Verify disabling the tracks of one MediaStream silences only its detector or all of them.

      const pairToDisable = pairs[0];
      const pairsToCheck = pairs.slice(1);

      async function disableStream() {
        const msg = await waitForStateChangedAfterAction(
          pairToDisable.detectorNode,
          async () => {
            pairToDisable.sourceNode.mediaStream
              .getTracks()
              .forEach((track) => {
                track.enabled = false;
              });
          }
        );
        assert_true(
          msg.data.isSilent,
          `Detector in context with rate ${pairToDisable.detectorNode.context.sampleRate} should be silent after disabling its stream.`
        );
      }

      // If MediaStreamTracks are shared across contexts, all detectors should be silent.
      // Otherwise, only the one with the stopped stream should be silent.
      if (cloneTracks) {
        await disableStream();
        await delay(
          calculateRequiredDelay(pairsToCheck.map((p) => p.detectorNode))
        );
        const msgs = await queryDetectorStates(pairsToCheck);
        msgs.forEach((msg, i) => {
          assert_false(
            msg.data.isSilent,
            `Detector in context with rate ${pairsToCheck[i].detectorNode.context.sampleRate} should not be silent after disabling the first stream.`
          );
        });
      } else {
        const msgs = await waitForStateChangedsAfterAction(
          pairsToCheck.map((p) => p.detectorNode),
          disableStream
        );
        msgs.forEach((msg, i) => {
          assert_true(
            msg.data.isSilent,
            `Detector in context with rate ${pairsToCheck[i].detectorNode.context.sampleRate} should be silent after disabling the first stream.`
          );
        });
      }

      // Clean up AudioContexts.

      for (const { ctx } of pairs) {
        await ctx.close();
      }
      input.ctx.close();
    }

    async function testRemovingTracksInOneMediaStream(
      tone,
      srcRate,
      dstRates,
      cloneTracks
    ) {
      assert_false(
        dstRates.includes(srcRate),
        "dstRates should not include srcRate."
      );

      const input = createSineWaveInput(srcRate, tone);
      const pairs = await createAndStartTestPairs(input, dstRates, cloneTracks);

      // Verify removing tracks from one MediaStream silences only its detector.

      const pairToModify = pairs[0];
      const pairsToCheck = pairs.slice(1);

      const tracks = pairToModify.sourceNode.mediaStream.getTracks();
      tracks.forEach((track) => {
        pairToModify.sourceNode.mediaStream.removeTrack(track);
      });

      await delay(
        calculateRequiredDelay(pairsToCheck.map((p) => p.detectorNode))
      );
      const msgs = await queryDetectorStates(pairsToCheck);
      msgs.forEach((msg, i) => {
        assert_false(
          msg.data.isSilent,
          `Detector in context with rate ${pairsToCheck[i].detectorNode.context.sampleRate} should not be silent after removing tracks from the first stream.`
        );
        assert_equals(
          msg.appendix.length,
          0,
          `Expected no additional messages for detector in context with rate ${pairsToCheck[i].detectorNode.context.sampleRate}.`
        );
      });

      // Clean up AudioContexts.

      for (const { ctx } of pairs) {
        await ctx.close();
      }
      input.ctx.close();
    }

    async function testStoppingInputStream(
      tone,
      srcRate,
      dstRates,
      cloneTracks
    ) {
      assert_false(
        dstRates.includes(srcRate),
        "dstRates should not include srcRate."
      );

      const input = createSineWaveInput(srcRate, tone);
      const pairs = await createAndStartTestPairs(input, dstRates, cloneTracks);

      // Verify stopping the original input stream silences nothing or all detectors.

      function stopInputStream() {
        input.dest.stream.getTracks().forEach((track) => track.stop());
      }

      // If MediaStreamTracks are cloned, all detectors should remain active.
      // If MediaStreamTracks are shared, all detectors should lose input when the source stream stops.
      if (cloneTracks) {
        stopInputStream();
        await delay(calculateRequiredDelay(pairs.map((p) => p.detectorNode)));
        const msgs = await queryDetectorStates(pairs);
        msgs.forEach((msg, i) => {
          assert_false(
            msg.data.isSilent,
            `Detector in context with rate ${pairs[i].detectorNode.context.sampleRate} should not be silent after stopping the input stream.`
          );
        });
      } else {
        const msgs = await waitForStateChangedsAfterAction(
          pairs.map((p) => p.detectorNode),
          stopInputStream
        );
        msgs.forEach((msg, i) => {
          assert_true(
            msg.data.isSilent || !msg.data.hasInput,
            `Detector in context with rate ${pairs[i].detectorNode.context.sampleRate} should be silent or have no input after stopping the shared input stream.`
          );
        });
      }

      // Clean up AudioContexts.

      for (const { ctx } of pairs) {
        await ctx.close();
      }
      input.ctx.close();
    }

    async function testSuspendingInputContextSilencesAll(
      tone,
      srcRate,
      dstRates,
      cloneTracks
    ) {
      assert_false(
        dstRates.includes(srcRate),
        "dstRates should not include srcRate."
      );

      const input = createSineWaveInput(srcRate, tone);
      const pairs = await createAndStartTestPairs(input, dstRates, cloneTracks);

      // Verify suspending the original input context silences all detectors.

      const msgs = await waitForStateChangedsAfterAction(
        pairs.map((p) => p.detectorNode),
        async () => {
          await input.ctx.suspend();
        }
      );
      msgs.forEach((msg, i) => {
        assert_true(
          msg.data.isSilent,
          `Detector in context with rate ${pairs[i].detectorNode.context.sampleRate} should be silent after suspending the input context.`
        );
      });

      // Clean up AudioContexts.

      for (const { ctx } of pairs) {
        await ctx.close();
      }
      input.ctx.close();
    }

    async function testClosingInputContextSilencesAll(
      tone,
      srcRate,
      dstRates,
      cloneTracks
    ) {
      assert_false(
        dstRates.includes(srcRate),
        "dstRates should not include srcRate."
      );

      const input = createSineWaveInput(srcRate, tone);
      const pairs = await createAndStartTestPairs(input, dstRates, cloneTracks);

      // Verify closing the original input context silences all detectors.

      const msgs = await waitForStateChangedsAfterAction(
        pairs.map((p) => p.detectorNode),
        async () => {
          await input.ctx.close();
        }
      );
      msgs.forEach((msg, i) => {
        assert_true(
          msg.data.isSilent,
          `Detector in context with rate ${pairs[i].detectorNode.context.sampleRate} should be silent after closing the input context.`
        );
      });

      // Clean up AudioContexts.
      for (const { ctx } of pairs) {
        await ctx.close();
      }
    }

    async function runAllTests(srcRate, dstRates, cloneTracks) {
      const notes = {
        C4: 261.63,
        D4: 293.66,
        E4: 329.63,
        F4: 349.23,
        G4: 392.0,
        A4: 440.0,
        B4: 493.88,
        C5: 523.25,
        D5: 587.33,
        E5: 659.25,
      };

      await testClosingOneContextStopsOnlyIt(
        notes.C4,
        srcRate,
        dstRates,
        cloneTracks
      );
      await testSuspendingOneContextSilencesOnlyIt(
        notes.D4,
        srcRate,
        dstRates,
        cloneTracks
      );
      await testDisconnectingOneSourceSilencesOnlyIt(
        notes.E4,
        srcRate,
        dstRates,
        cloneTracks
      );
      await testStoppingOneMediaStream(
        notes.F4,
        srcRate,
        dstRates,
        cloneTracks
      );
      await testDisablingOneMediaStream(
        notes.G4,
        srcRate,
        dstRates,
        cloneTracks
      );
      await testRemovingTracksInOneMediaStream(
        notes.A4,
        srcRate,
        dstRates,
        cloneTracks
      );
      await testStoppingInputStream(notes.B4, srcRate, dstRates, cloneTracks);
      await testSuspendingInputContextSilencesAll(
        notes.C5,
        srcRate,
        dstRates,
        cloneTracks
      );
      await testClosingInputContextSilencesAll(
        notes.D5,
        srcRate,
        dstRates,
        cloneTracks
      );

      // Tests for destination contexts have identical sample rates
      for (let i = 0; i < dstRates.length; i++) {
        const rates = [dstRates[i], dstRates[i]];
        const tone = notes.E5 * Math.pow(2, i / 12);
        await testRemovingTracksInOneMediaStream(
          tone,
          srcRate,
          rates,
          cloneTracks
        );
      }
    }

    async function run() {
      const srcRate = 44100;
      const dstRates = [32000, 48000, 96000];
      const trackUsages = { cloned: true, shared: false };

      // Tests with shared MediaStreamTracks.
      await runAllTests(srcRate, dstRates, trackUsages.shared);

      // Tests with cloned MediaStreamTracks.
      await runAllTests(srcRate, dstRates, trackUsages.cloned);

      console.log("All tests completed.");
    }

    window.addEventListener("DOMContentLoaded", (event) => {
      const btn = document.createElement("button");
      btn.textContent = "start";
      document.body.appendChild(btn);

      btn.addEventListener("click", async () => {
        btn.disabled = true;
        btn.textContent = "running...";

        await run();

        btn.textContent = "start";
        btn.disabled = false;
      });
    });
  </script>
  <body>
    <p>
      Testing MediaStreamAudioSourceNode using a MediaStream with a sample rate
      different from the AudioContext.
    </p>
  </body>
</html>
